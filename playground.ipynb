{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook \\#1 - Operator Learning and Optimal Control "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this beginning notebook, I am going to construct a framework for the learning of neural operator using DeepONet architecture and solve Diffusion Problem (to be explained later). The structure of this notebook goes as follows:\n",
    "- Implement a class for the DeepONet architecture\n",
    "- Implement a function for training of the DeepONet with given differential equation and innitial/boundary conditions \n",
    "- Generate a training dataset for the input control functions and the corresponding analytical solutions of the differential equation\n",
    "- Define loss functions associated with physics loss, innitial and boundary conditions\n",
    "- Train the DeepONet\n",
    "- Solve Feldbaum Problem\n",
    "\n",
    "\n",
    "Let's start by implementing the DeepONet architecture.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from datetime import datetime\n",
    "from utils.data import MultiFunctionDatasetODE, custom_collate_ODE_fn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import utils.plotter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implemention of the DeepONet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DenseNetwork(nn.Module)` takes as input 2 vectors: `layer_sizes` (size of each layer of NN including input and output sizes) and `activations` (activation function after each layer, available options include: 'relu', 'tanh', 'sigmoid', 'leaky_relu', 'elu', 'none'). This function is just a way to initialize a simple neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, activations):\n",
    "        super(DenseNetwork, self).__init__()\n",
    "        assert len(layer_sizes) - 1 == len(activations), \"Activation count must match the number of layers - 1\"\n",
    "        \n",
    "        layers = []\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            layers.append(nn.Linear(layer_sizes[i], layer_sizes[i + 1]))\n",
    "            if activations[i] is not None:\n",
    "                layers.append(self.get_activation(activations[i]))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "        # Apply Glorot initialization\n",
    "        self.apply(self.initialize_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_activation(name):\n",
    "        activations = {\n",
    "            'relu': nn.ReLU(),\n",
    "            'tanh': nn.Tanh(),\n",
    "            'sigmoid': nn.Sigmoid(),\n",
    "            'leaky_relu': nn.LeakyReLU(),\n",
    "            'elu': nn.ELU(),\n",
    "            'none': nn.Identity()\n",
    "        }\n",
    "        if name not in activations:\n",
    "            raise ValueError(f\"Unsupported activation: {name}. Supported: {list(activations.keys())}\")\n",
    "        return activations[name]\n",
    "\n",
    "    @staticmethod\n",
    "    def initialize_weights(layer):\n",
    "\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            init.xavier_uniform_(layer.weight)\n",
    "            if layer.bias is not None:\n",
    "                init.zeros_(layer.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeepOnet has the following structure:\n",
    "- There are two neural networks: branch and trunk NNs\n",
    "- Each NN has its own output vector\n",
    "- Dot product of these two vectors is output vector of the DeepOnet\n",
    "\n",
    "The architecture can be see at the Figure 1.\n",
    "\n",
    "<center><img src=\"https://www.researchgate.net/publication/369528434/figure/fig1/AS:11431281157276229@1683770151535/DeepONet-architecture-stacked-42-used-in-the-present-study.png\" width=\"800px\">\n",
    "<p>Figure 1 - Architecture of the DeepONet</p>\n",
    "</center>\n",
    "\n",
    "So, to initialize DeepONet, we need to create 2 neural networks with architectures provided by users and combine their outputs. Using class `DenseNetwork`, we can initialize branch and trunk NNs. Forward method of `DeepONet` can be calculated using `torch.einsum` functions that would combine forward passes of these 2 NNs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepONetCartesianProd(nn.Module):\n",
    "    def __init__(self, branch_net, trunk_net, branch_activations, trunk_activations, input_feature=None):\n",
    "        super(DeepONetCartesianProd, self).__init__()\n",
    "        self.branch_net = DenseNetwork(branch_net, branch_activations)\n",
    "        self.trunk_net = DenseNetwork(trunk_net, trunk_activations)\n",
    "\n",
    "\n",
    "        if input_feature is not None:\n",
    "            self.input_encode = input_feature\n",
    "        else:\n",
    "            self.input_encode = None\n",
    "\n",
    "\n",
    "    def forward(self, branch_input, trunk_input):\n",
    "\n",
    "        branch_output = self.branch_net(branch_input)  # Shape: (batch_size, branch_net[-1])\n",
    "        \n",
    "        if self.input_encode is not None:\n",
    "            trunk_input = self.input_encode(trunk_input)\n",
    "        \n",
    "        trunk_output = self.trunk_net(trunk_input)    # Shape: (batch_size, trunk_net[-1])\n",
    "        output = torch.einsum(\"bp,np->bn\", branch_output, trunk_output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement `training()` of the DeepONet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this function `training()`, I tried to be as generic as possible. The function takes as input `model` (created using class `DeepONetCartesianProd`), `optimizer` (for example `Adam`), `dataloader` (created specifically for the problem) and functions that will calculate specific losses that are associated with the problem (`physics_loss_func()`, `initial_loss_func()`, `boundary_loss_func()`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, optimizer, dataloader, num_epochs= 1000, physics_loss_func=None, initial_loss_func=None, boundary_loss_func= None, plot=False):\n",
    "    losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for u, t, t0, ut in dataloader:\n",
    "\n",
    "            t.requires_grad_(True)\n",
    "            batch_size = u.shape[0]\n",
    "            n_points = t.shape[0]\n",
    "\n",
    "            physics_loss = physics_loss_func(model, u, t, t0, ut, batch_size, n_points) if physics_loss_func is not None else torch.zeros(1, device=t.device)\n",
    "            initial_loss = initial_loss_func(model, u, t, t0, ut, batch_size, n_points) if initial_loss_func is not None else torch.zeros(1, device=t.device)\n",
    "            boundary_loss = boundary_loss_func(model, u, t, t0, ut, batch_size, n_points) if boundary_loss_func is not None else torch.zeros(1, device=t.device)\n",
    "            # Total loss\n",
    "            loss = physics_loss + initial_loss + boundary_loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, '\n",
    "                    f'initial_loss: {initial_loss.item():.6f}, physics_loss: {physics_loss.item():.6f}, '\n",
    "                    f'time: {datetime.now().time()}')\n",
    "            \n",
    "            if plot == True:\n",
    "                plotter.GRF_test(model,m=m,lb=grf_lb,ub=grf_ub)\n",
    "                plotter.linear_test(model,m=m)\n",
    "                plotter.optimal_test(model,m=m)\n",
    "                plotter.constant_test(model, m=m)\n",
    "                plotter.polynomial_test(model, m=m)\n",
    "                plotter.sine_test(model, m=m)\n",
    "        \n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "            model_filename = f'model_time_[{timestamp}]_loss_[{loss.item():.4f}].pth'\n",
    "            torch.save(model.state_dict(), f\"trained_models/deep_o_net/{model_filename}\")\n",
    "                        \n",
    "\n",
    "\n",
    "        losses.append(loss)\n",
    "\n",
    "\n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define loss functions specific to the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, I will implement the loss functions for the simple Feldbaum problem. The Feldbaum problem is defined as follows:\n",
    "$$\\text{min}_u \\ \\int_{0}^{1} (x^2 + u^2)dt$$\n",
    "$$\\text{s.t.} \\ \\frac{dx}{dt} = x - u$$\n",
    "$$ x(0) = 1$$\n",
    "\n",
    "Additionally, I added an initial condition that $x(t_0) = 1$\n",
    "\n",
    "The physics loss refers to differential equation being non-violated. Ideally,\n",
    "$$\\frac{dx}{dt} - x + u = 0$$\n",
    "\n",
    "where $u$ is input function, $x$ is solution found by neural operator and $x_t$ can be found using `autograd` function which is part of `torch` functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def physics_loss_func(model, u, t, t0, ut, batch_size, n_points, dim_x = 1):\n",
    "\n",
    "    x = model(u, t)\n",
    "\n",
    "    # Physics loss\n",
    "    dx = torch.zeros(batch_size, n_points, dim_x, device=t.device)\n",
    "    \n",
    "    # This loop is a bottleneck but i havent found a way to parallize this efficiently\n",
    "    for b in range(batch_size):\n",
    "        # Compute gradients for each batch independently\n",
    "        dx[b] = torch.autograd.grad(x[b], t, torch.ones_like(x[b]), create_graph=True)[0]\n",
    "\n",
    "    dx_dt = dx[:,:,0]\n",
    "\n",
    "    # physics loss\n",
    "    physics = dx_dt + x - u\n",
    "    physics_loss = torch.mean(physics**2)\n",
    "\n",
    "    return physics_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, in the function `physics_loss_func`  we extract the $x_t$ from each batch. `physics` stores the differential equation that we shouldn't violate. And final `physics_loss` is a mean squared error. \n",
    "\n",
    "As input parameters, it takes all the information from the training dataset and output of the neural network `x`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Innitial loss function is easy in our case. The output of the neural network at $t=0$ just should be 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def innitial_loss_func(model, u, t, t0, ut, batch_size, n_points):\n",
    "\n",
    "    x_0 = model(u, t0)\n",
    "    initial_loss = torch.mean((torch.ones_like(x_0) - x_0)**2)\n",
    "    \n",
    "    return initial_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate model and training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define number of layers of NNs and number of neurons at each layer. The output size of both trunk and branch networks should be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "m = 200         # sensor size (branch input size)\n",
    "n_hid = 250     # layer's hidden sizes\n",
    "p = 200         # output size\n",
    "dim_x = 1       # trunk (trunk input size)\n",
    "lr = 0.0001\n",
    "num_epochs = 1000\n",
    "\n",
    "# Specify device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Specify the MLP architecture\n",
    "branch_net = [m, n_hid, n_hid, n_hid, n_hid, p]\n",
    "branch_activations = ['tanh', 'tanh','tanh', 'tanh', None]\n",
    "trunk_net = [dim_x, n_hid, n_hid, n_hid, n_hid, p]\n",
    "trunk_activations = ['tanh', 'tanh', 'tanh', 'tanh',None]\n",
    "\n",
    "# Initialize model\n",
    "model = DeepONetCartesianProd(branch_net, trunk_net, branch_activations, trunk_activations)\n",
    "model.to(device)\n",
    "\n",
    "#Initialize Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we generate all possible candidates for the the control function $u(t)$. We want to train our DeepONet on a diverse domain of functions. In this case we train model on next families of functions: `grf`, `linear`, `sine`, `polynomial`, `constant`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset parameters\n",
    "n_functions = 10000\n",
    "grf_lb = 0.02\n",
    "grf_ub = 0.5\n",
    "end_time = 1.0\n",
    "num_domain = 200\n",
    "num_initial = 20\n",
    "\n",
    "dataset = MultiFunctionDatasetODE(\n",
    "    m=m,\n",
    "    n_functions=n_functions,\n",
    "    function_types=['grf', 'linear', 'sine', 'polynomial','constant'],\n",
    "    end_time = end_time,\n",
    "    num_domain = num_domain,\n",
    "    num_initial = num_initial,\n",
    "    grf_lb = grf_lb,\n",
    "    grf_ub = grf_ub\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=128, collate_fn=custom_collate_ODE_fn, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train DeepONet model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we should have everything to train the DeepONet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/1000], Loss: 0.6212, initial_loss: 0.003512, physics_loss: 0.617734, time: 20:26:18.927755\n",
      "Epoch [20/1000], Loss: 0.5012, initial_loss: 0.001404, physics_loss: 0.499840, time: 20:27:19.947396\n",
      "Epoch [30/1000], Loss: 0.3342, initial_loss: 0.001006, physics_loss: 0.333221, time: 20:28:21.529175\n",
      "Epoch [40/1000], Loss: 1.1026, initial_loss: 0.000535, physics_loss: 1.102091, time: 20:29:24.785795\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trained_model, lossses \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphysics_loss_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mphysics_loss_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_loss_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minnitial_loss_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[77], line 11\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(model, optimizer, dataloader, num_epochs, physics_loss_func, initial_loss_func, boundary_loss_func, plot)\u001b[0m\n\u001b[1;32m      8\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      9\u001b[0m n_points \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 11\u001b[0m physics_loss \u001b[38;5;241m=\u001b[39m \u001b[43mphysics_loss_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mut\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_points\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m physics_loss_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, device\u001b[38;5;241m=\u001b[39mt\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     12\u001b[0m initial_loss \u001b[38;5;241m=\u001b[39m initial_loss_func(model, u, t, t0, ut, batch_size, n_points) \u001b[38;5;28;01mif\u001b[39;00m initial_loss_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, device\u001b[38;5;241m=\u001b[39mt\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     13\u001b[0m boundary_loss \u001b[38;5;241m=\u001b[39m boundary_loss_func(model, u, t, t0, ut, batch_size, n_points) \u001b[38;5;28;01mif\u001b[39;00m boundary_loss_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, device\u001b[38;5;241m=\u001b[39mt\u001b[38;5;241m.\u001b[39mdevice)\n",
      "Cell \u001b[0;32mIn[83], line 11\u001b[0m, in \u001b[0;36mphysics_loss_func\u001b[0;34m(model, u, t, t0, ut, batch_size, n_points, dim_x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# This loop is a bottleneck but i havent found a way to parallize this efficiently\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Compute gradients for each batch independently\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     dx[b] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(x[b], t, \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     13\u001b[0m dx_dt \u001b[38;5;241m=\u001b[39m dx[:,:,\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# physics loss\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained_model, lossses = training(model, optimizer, dataloader, num_epochs = num_epochs, physics_loss_func=physics_loss_func, initial_loss_func=innitial_loss_func, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepONetCartesianProd(\n",
       "  (branch_net): DenseNetwork(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=200, out_features=250, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=250, out_features=250, bias=True)\n",
       "      (3): Tanh()\n",
       "      (4): Linear(in_features=250, out_features=250, bias=True)\n",
       "      (5): Tanh()\n",
       "      (6): Linear(in_features=250, out_features=250, bias=True)\n",
       "      (7): Tanh()\n",
       "      (8): Linear(in_features=250, out_features=200, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (trunk_net): DenseNetwork(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=1, out_features=250, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=250, out_features=250, bias=True)\n",
       "      (3): Tanh()\n",
       "      (4): Linear(in_features=250, out_features=250, bias=True)\n",
       "      (5): Tanh()\n",
       "      (6): Linear(in_features=250, out_features=250, bias=True)\n",
       "      (7): Tanh()\n",
       "      (8): Linear(in_features=250, out_features=200, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model =  DeepONetCartesianProd(branch_net, trunk_net, branch_activations, trunk_activations)\n",
    "trained_model.to(device)\n",
    "trained_model.load_state_dict(torch.load('trained_models/deep_o_net/model_time_[20250306-123131]_loss_[0.0134].pth'))\n",
    "trained_model.eval()  # set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve Feldbaum problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we just trained neural operator to approximate $x$ for given input control function $u$, but we haven't touched optimization part yet. I will remind you what is the problem that we are trying to solve:\n",
    "\n",
    "$$\\text{min}_u \\ \\ \\frac{1}{2}\\int_{0}^{1} (x^2 + u^2)dt$$\n",
    "$$\\text{s.t.} \\ \\frac{dx}{dt} = x - u$$\n",
    "$$ x(0) = 1$$\n",
    "\n",
    "So, we should find such control function $u$ that this integral is minimized \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(n, args):\n",
    "\n",
    "    # Physics loss\n",
    "    dx = torch.zeros(n, args['t'].shape[0], dim_x, device=args['t'].device)\n",
    "    \n",
    "    # This loop is a bottleneck but i havent found a way to parallize this efficiently\n",
    "    for b in range(n):\n",
    "        # Compute gradients for each batch independently\n",
    "        dx[b] = torch.autograd.grad(args['x'][b], args['t'], torch.ones_like(args['x'][b]), create_graph=True)[0]\n",
    "\n",
    "    dx_dt = dx[:,:,0]\n",
    "\n",
    "    # physics loss\n",
    "    physics = dx_dt + args['x'] - args['u']\n",
    "    physics_loss = torch.mean(physics**2)\n",
    "    innitial_loss_func = torch.mean((args['x'][:, 0] - torch.ones(n, device= device))**2)\n",
    "\n",
    "    J = torch.mean(torch.trapz((args['x']**2 + args['u']**2).squeeze(), args['t'].squeeze()))  + 100 * physics_loss + 10*innitial_loss_func \n",
    "    return J\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(n, alpha, m, num_epochs, model, objective_function):  \n",
    "    \n",
    "    u = torch.randn(n, m, device= device)\n",
    "    t = torch.linspace(0, end_time, m, device= device).unsqueeze(1) \n",
    "    \n",
    "    u.requires_grad_(True)\n",
    "    t.requires_grad_(True)\n",
    "\n",
    "    optimizer = torch.optim.AdamW([u], lr=alpha, weight_decay=0.01)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        x = model(u, t) \n",
    "        args = {'x': x, 'u': u, 't': t}\n",
    "        loss = objective_function(n, args)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        if (epoch+1) % 100 == 0:\n",
    "            \n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, time: {datetime.now().time()}')\n",
    "\n",
    "    return torch.mean(u, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/30000], Loss: 141.5811, time: 20:48:29.753283\n",
      "Epoch [200/30000], Loss: 138.0668, time: 20:48:30.658168\n",
      "Epoch [300/30000], Loss: 134.6955, time: 20:48:31.558905\n",
      "Epoch [400/30000], Loss: 131.4514, time: 20:48:32.450387\n",
      "Epoch [500/30000], Loss: 128.3233, time: 20:48:33.342530\n",
      "Epoch [600/30000], Loss: 125.3022, time: 20:48:34.232531\n",
      "Epoch [700/30000], Loss: 122.3809, time: 20:48:35.123924\n",
      "Epoch [800/30000], Loss: 119.5535, time: 20:48:36.016152\n",
      "Epoch [900/30000], Loss: 116.8154, time: 20:48:36.928246\n",
      "Epoch [1000/30000], Loss: 114.1625, time: 20:48:37.823906\n",
      "Epoch [1100/30000], Loss: 111.5913, time: 20:48:38.726467\n",
      "Epoch [1200/30000], Loss: 109.0986, time: 20:48:39.621170\n",
      "Epoch [1300/30000], Loss: 106.6811, time: 20:48:40.528017\n",
      "Epoch [1400/30000], Loss: 104.3360, time: 20:48:41.423915\n",
      "Epoch [1500/30000], Loss: 102.0603, time: 20:48:42.337469\n",
      "Epoch [1600/30000], Loss: 99.8512, time: 20:48:43.229007\n",
      "Epoch [1700/30000], Loss: 97.7061, time: 20:48:44.108980\n",
      "Epoch [1800/30000], Loss: 95.6223, time: 20:48:44.993755\n",
      "Epoch [1900/30000], Loss: 93.5975, time: 20:48:45.873369\n",
      "Epoch [2000/30000], Loss: 91.6291, time: 20:48:46.754601\n",
      "Epoch [2100/30000], Loss: 89.7151, time: 20:48:47.650729\n",
      "Epoch [2200/30000], Loss: 87.8531, time: 20:48:48.571989\n",
      "Epoch [2300/30000], Loss: 86.0413, time: 20:48:49.559411\n",
      "Epoch [2400/30000], Loss: 84.2775, time: 20:48:50.450699\n",
      "Epoch [2500/30000], Loss: 82.5601, time: 20:48:51.340303\n",
      "Epoch [2600/30000], Loss: 80.8873, time: 20:48:52.221120\n",
      "Epoch [2700/30000], Loss: 79.2573, time: 20:48:53.101381\n",
      "Epoch [2800/30000], Loss: 77.6686, time: 20:48:53.983834\n",
      "Epoch [2900/30000], Loss: 76.1196, time: 20:48:54.863666\n",
      "Epoch [3000/30000], Loss: 74.6087, time: 20:48:55.754525\n",
      "Epoch [3100/30000], Loss: 73.1346, time: 20:48:56.634192\n",
      "Epoch [3200/30000], Loss: 71.6957, time: 20:48:57.527478\n",
      "Epoch [3300/30000], Loss: 70.2906, time: 20:48:58.425169\n",
      "Epoch [3400/30000], Loss: 68.9178, time: 20:48:59.308010\n",
      "Epoch [3500/30000], Loss: 67.5762, time: 20:49:00.190600\n",
      "Epoch [3600/30000], Loss: 66.2643, time: 20:49:01.072192\n",
      "Epoch [3700/30000], Loss: 64.9808, time: 20:49:01.952939\n",
      "Epoch [3800/30000], Loss: 63.7247, time: 20:49:02.834373\n",
      "Epoch [3900/30000], Loss: 62.4947, time: 20:49:03.719175\n",
      "Epoch [4000/30000], Loss: 61.2897, time: 20:49:04.610125\n",
      "Epoch [4100/30000], Loss: 60.1088, time: 20:49:05.491603\n",
      "Epoch [4200/30000], Loss: 58.9509, time: 20:49:06.367809\n",
      "Epoch [4300/30000], Loss: 57.8152, time: 20:49:07.245661\n",
      "Epoch [4400/30000], Loss: 56.7007, time: 20:49:08.140408\n",
      "Epoch [4500/30000], Loss: 55.6067, time: 20:49:09.021881\n",
      "Epoch [4600/30000], Loss: 54.5324, time: 20:49:09.900794\n",
      "Epoch [4700/30000], Loss: 53.4771, time: 20:49:10.784490\n",
      "Epoch [4800/30000], Loss: 52.4402, time: 20:49:11.688043\n",
      "Epoch [4900/30000], Loss: 51.4210, time: 20:49:12.566685\n",
      "Epoch [5000/30000], Loss: 50.4191, time: 20:49:13.445055\n",
      "Epoch [5100/30000], Loss: 49.4339, time: 20:49:14.324474\n",
      "Epoch [5200/30000], Loss: 48.4650, time: 20:49:15.209890\n",
      "Epoch [5300/30000], Loss: 47.5119, time: 20:49:16.095275\n",
      "Epoch [5400/30000], Loss: 46.5742, time: 20:49:16.980376\n",
      "Epoch [5500/30000], Loss: 45.6516, time: 20:49:17.872761\n",
      "Epoch [5600/30000], Loss: 44.7438, time: 20:49:18.769184\n",
      "Epoch [5700/30000], Loss: 43.8505, time: 20:49:19.657953\n",
      "Epoch [5800/30000], Loss: 42.9713, time: 20:49:20.537369\n",
      "Epoch [5900/30000], Loss: 42.1062, time: 20:49:21.417083\n",
      "Epoch [6000/30000], Loss: 41.2547, time: 20:49:22.296056\n",
      "Epoch [6100/30000], Loss: 40.4168, time: 20:49:23.175073\n",
      "Epoch [6200/30000], Loss: 39.5922, time: 20:49:24.054126\n",
      "Epoch [6300/30000], Loss: 38.7807, time: 20:49:24.936898\n",
      "Epoch [6400/30000], Loss: 37.9822, time: 20:49:25.838873\n",
      "Epoch [6500/30000], Loss: 37.1964, time: 20:49:26.727906\n",
      "Epoch [6600/30000], Loss: 36.4232, time: 20:49:27.605729\n",
      "Epoch [6700/30000], Loss: 35.6625, time: 20:49:28.483971\n",
      "Epoch [6800/30000], Loss: 34.9141, time: 20:49:29.380450\n",
      "Epoch [6900/30000], Loss: 34.1778, time: 20:49:30.271416\n",
      "Epoch [7000/30000], Loss: 33.4535, time: 20:49:31.155978\n",
      "Epoch [7100/30000], Loss: 32.7410, time: 20:49:32.035510\n",
      "Epoch [7200/30000], Loss: 32.0403, time: 20:49:32.927364\n",
      "Epoch [7300/30000], Loss: 31.3510, time: 20:49:33.825011\n",
      "Epoch [7400/30000], Loss: 30.6732, time: 20:49:34.712316\n",
      "Epoch [7500/30000], Loss: 30.0067, time: 20:49:35.593785\n",
      "Epoch [7600/30000], Loss: 29.3512, time: 20:49:36.477187\n",
      "Epoch [7700/30000], Loss: 28.7068, time: 20:49:37.366543\n",
      "Epoch [7800/30000], Loss: 28.0732, time: 20:49:38.247308\n",
      "Epoch [7900/30000], Loss: 27.4504, time: 20:49:39.139433\n",
      "Epoch [8000/30000], Loss: 26.8382, time: 20:49:40.022057\n",
      "Epoch [8100/30000], Loss: 26.2364, time: 20:49:40.912289\n",
      "Epoch [8200/30000], Loss: 25.6450, time: 20:49:41.807873\n",
      "Epoch [8300/30000], Loss: 25.0639, time: 20:49:42.691882\n",
      "Epoch [8400/30000], Loss: 24.4929, time: 20:49:43.573854\n",
      "Epoch [8500/30000], Loss: 23.9318, time: 20:49:44.463539\n",
      "Epoch [8600/30000], Loss: 23.3807, time: 20:49:45.357510\n",
      "Epoch [8700/30000], Loss: 22.8393, time: 20:49:46.242599\n",
      "Epoch [8800/30000], Loss: 22.3075, time: 20:49:47.127346\n",
      "Epoch [8900/30000], Loss: 21.7853, time: 20:49:48.020796\n",
      "Epoch [9000/30000], Loss: 21.2725, time: 20:49:48.920739\n",
      "Epoch [9100/30000], Loss: 20.7691, time: 20:49:49.821191\n",
      "Epoch [9200/30000], Loss: 20.2748, time: 20:49:50.713980\n",
      "Epoch [9300/30000], Loss: 19.7896, time: 20:49:51.599016\n",
      "Epoch [9400/30000], Loss: 19.3134, time: 20:49:52.483327\n",
      "Epoch [9500/30000], Loss: 18.8461, time: 20:49:53.369062\n",
      "Epoch [9600/30000], Loss: 18.3876, time: 20:49:54.253076\n",
      "Epoch [9700/30000], Loss: 17.9377, time: 20:49:55.133857\n",
      "Epoch [9800/30000], Loss: 17.4964, time: 20:49:56.025861\n",
      "Epoch [9900/30000], Loss: 17.0636, time: 20:49:56.911079\n",
      "Epoch [10000/30000], Loss: 16.6391, time: 20:49:57.793740\n",
      "Epoch [10100/30000], Loss: 16.2229, time: 20:49:58.674990\n",
      "Epoch [10200/30000], Loss: 15.8148, time: 20:49:59.556114\n",
      "Epoch [10300/30000], Loss: 15.4148, time: 20:50:00.454764\n",
      "Epoch [10400/30000], Loss: 15.0227, time: 20:50:01.339389\n",
      "Epoch [10500/30000], Loss: 14.6385, time: 20:50:02.227027\n",
      "Epoch [10600/30000], Loss: 14.2620, time: 20:50:03.121870\n",
      "Epoch [10700/30000], Loss: 13.8932, time: 20:50:04.007837\n",
      "Epoch [10800/30000], Loss: 13.5319, time: 20:50:04.893112\n",
      "Epoch [10900/30000], Loss: 13.1780, time: 20:50:05.777168\n",
      "Epoch [11000/30000], Loss: 12.8315, time: 20:50:06.661882\n",
      "Epoch [11100/30000], Loss: 12.4922, time: 20:50:07.542512\n",
      "Epoch [11200/30000], Loss: 12.1601, time: 20:50:08.424400\n",
      "Epoch [11300/30000], Loss: 11.8350, time: 20:50:09.311903\n",
      "Epoch [11400/30000], Loss: 11.5169, time: 20:50:10.207507\n",
      "Epoch [11500/30000], Loss: 11.2056, time: 20:50:11.108202\n",
      "Epoch [11600/30000], Loss: 10.9011, time: 20:50:11.995576\n",
      "Epoch [11700/30000], Loss: 10.6032, time: 20:50:12.877749\n",
      "Epoch [11800/30000], Loss: 10.3120, time: 20:50:13.760987\n",
      "Epoch [11900/30000], Loss: 10.0272, time: 20:50:14.647449\n",
      "Epoch [12000/30000], Loss: 9.7488, time: 20:50:15.534590\n",
      "Epoch [12100/30000], Loss: 9.4767, time: 20:50:16.418609\n",
      "Epoch [12200/30000], Loss: 9.2108, time: 20:50:17.311648\n",
      "Epoch [12300/30000], Loss: 8.9510, time: 20:50:18.220152\n",
      "Epoch [12400/30000], Loss: 8.6972, time: 20:50:19.118933\n",
      "Epoch [12500/30000], Loss: 8.4494, time: 20:50:20.012506\n",
      "Epoch [12600/30000], Loss: 8.2074, time: 20:50:20.904825\n",
      "Epoch [12700/30000], Loss: 7.9711, time: 20:50:21.827370\n",
      "Epoch [12800/30000], Loss: 7.7406, time: 20:50:22.728070\n",
      "Epoch [12900/30000], Loss: 7.5156, time: 20:50:23.621287\n",
      "Epoch [13000/30000], Loss: 7.2960, time: 20:50:24.512576\n",
      "Epoch [13100/30000], Loss: 7.0819, time: 20:50:25.403800\n",
      "Epoch [13200/30000], Loss: 6.8730, time: 20:50:26.302916\n",
      "Epoch [13300/30000], Loss: 6.6694, time: 20:50:27.203915\n",
      "Epoch [13400/30000], Loss: 6.4709, time: 20:50:28.100988\n",
      "Epoch [13500/30000], Loss: 6.2775, time: 20:50:28.996087\n",
      "Epoch [13600/30000], Loss: 6.0890, time: 20:50:29.891547\n",
      "Epoch [13700/30000], Loss: 5.9053, time: 20:50:30.782012\n",
      "Epoch [13800/30000], Loss: 5.7265, time: 20:50:31.686298\n",
      "Epoch [13900/30000], Loss: 5.5523, time: 20:50:32.586467\n",
      "Epoch [14000/30000], Loss: 5.3828, time: 20:50:33.483342\n",
      "Epoch [14100/30000], Loss: 5.2178, time: 20:50:34.382526\n",
      "Epoch [14200/30000], Loss: 5.0573, time: 20:50:35.271603\n",
      "Epoch [14300/30000], Loss: 4.9011, time: 20:50:36.167032\n",
      "Epoch [14400/30000], Loss: 4.7493, time: 20:50:37.057246\n",
      "Epoch [14500/30000], Loss: 4.6016, time: 20:50:37.947737\n",
      "Epoch [14600/30000], Loss: 4.4581, time: 20:50:38.844574\n",
      "Epoch [14700/30000], Loss: 4.3186, time: 20:50:39.734593\n",
      "Epoch [14800/30000], Loss: 4.1832, time: 20:50:40.625242\n",
      "Epoch [14900/30000], Loss: 4.0516, time: 20:50:41.520274\n",
      "Epoch [15000/30000], Loss: 3.9238, time: 20:50:42.426697\n",
      "Epoch [15100/30000], Loss: 3.7998, time: 20:50:43.329239\n",
      "Epoch [15200/30000], Loss: 3.6794, time: 20:50:44.226368\n",
      "Epoch [15300/30000], Loss: 3.5627, time: 20:50:45.121431\n",
      "Epoch [15400/30000], Loss: 3.4494, time: 20:50:46.018753\n",
      "Epoch [15500/30000], Loss: 3.3396, time: 20:50:46.917755\n",
      "Epoch [15600/30000], Loss: 3.2332, time: 20:50:47.807823\n",
      "Epoch [15700/30000], Loss: 3.1300, time: 20:50:48.697902\n",
      "Epoch [15800/30000], Loss: 3.0301, time: 20:50:49.594713\n",
      "Epoch [15900/30000], Loss: 2.9333, time: 20:50:50.487821\n",
      "Epoch [16000/30000], Loss: 2.8396, time: 20:50:51.382672\n",
      "Epoch [16100/30000], Loss: 2.7489, time: 20:50:52.275755\n",
      "Epoch [16200/30000], Loss: 2.6611, time: 20:50:53.190130\n",
      "Epoch [16300/30000], Loss: 2.5762, time: 20:50:54.087012\n",
      "Epoch [16400/30000], Loss: 2.4941, time: 20:50:54.982965\n",
      "Epoch [16500/30000], Loss: 2.4147, time: 20:50:55.874241\n",
      "Epoch [16600/30000], Loss: 2.3379, time: 20:50:56.765066\n",
      "Epoch [16700/30000], Loss: 2.2638, time: 20:50:57.659957\n",
      "Epoch [16800/30000], Loss: 2.1921, time: 20:50:58.555175\n",
      "Epoch [16900/30000], Loss: 2.1230, time: 20:50:59.447897\n",
      "Epoch [17000/30000], Loss: 2.0562, time: 20:51:00.347080\n",
      "Epoch [17100/30000], Loss: 1.9918, time: 20:51:01.240907\n",
      "Epoch [17200/30000], Loss: 1.9296, time: 20:51:02.129678\n",
      "Epoch [17300/30000], Loss: 1.8697, time: 20:51:03.026058\n",
      "Epoch [17400/30000], Loss: 1.8119, time: 20:51:03.937684\n",
      "Epoch [17500/30000], Loss: 1.7562, time: 20:51:04.835504\n",
      "Epoch [17600/30000], Loss: 1.7025, time: 20:51:05.730030\n",
      "Epoch [17700/30000], Loss: 1.6508, time: 20:51:06.646234\n",
      "Epoch [17800/30000], Loss: 1.6010, time: 20:51:07.554082\n",
      "Epoch [17900/30000], Loss: 1.5531, time: 20:51:08.457670\n",
      "Epoch [18000/30000], Loss: 1.5070, time: 20:51:09.349866\n",
      "Epoch [18100/30000], Loss: 1.4627, time: 20:51:10.250710\n",
      "Epoch [18200/30000], Loss: 1.4201, time: 20:51:11.151603\n",
      "Epoch [18300/30000], Loss: 1.3791, time: 20:51:12.041239\n",
      "Epoch [18400/30000], Loss: 1.3398, time: 20:51:12.916658\n",
      "Epoch [18500/30000], Loss: 1.3019, time: 20:51:13.793524\n",
      "Epoch [18600/30000], Loss: 1.2656, time: 20:51:14.671305\n",
      "Epoch [18700/30000], Loss: 1.2308, time: 20:51:15.609137\n",
      "Epoch [18800/30000], Loss: 1.1973, time: 20:51:16.507969\n",
      "Epoch [18900/30000], Loss: 1.1652, time: 20:51:17.412187\n",
      "Epoch [19000/30000], Loss: 1.1344, time: 20:51:18.305191\n",
      "Epoch [19100/30000], Loss: 1.1049, time: 20:51:19.196688\n",
      "Epoch [19200/30000], Loss: 1.0766, time: 20:51:20.095131\n",
      "Epoch [19300/30000], Loss: 1.0494, time: 20:51:20.990386\n",
      "Epoch [19400/30000], Loss: 1.0234, time: 20:51:21.889233\n",
      "Epoch [19500/30000], Loss: 0.9985, time: 20:51:22.782097\n",
      "Epoch [19600/30000], Loss: 0.9746, time: 20:51:23.671604\n",
      "Epoch [19700/30000], Loss: 0.9517, time: 20:51:24.582932\n",
      "Epoch [19800/30000], Loss: 0.9298, time: 20:51:25.477680\n",
      "Epoch [19900/30000], Loss: 0.9088, time: 20:51:26.374696\n",
      "Epoch [20000/30000], Loss: 0.8886, time: 20:51:27.268937\n",
      "Epoch [20100/30000], Loss: 0.8694, time: 20:51:28.162582\n",
      "Epoch [20200/30000], Loss: 0.8509, time: 20:51:29.060538\n",
      "Epoch [20300/30000], Loss: 0.8332, time: 20:51:29.956650\n",
      "Epoch [20400/30000], Loss: 0.8162, time: 20:51:30.845729\n",
      "Epoch [20500/30000], Loss: 0.8000, time: 20:51:31.737768\n",
      "Epoch [20600/30000], Loss: 0.7844, time: 20:51:32.624172\n",
      "Epoch [20700/30000], Loss: 0.7695, time: 20:51:33.524021\n",
      "Epoch [20800/30000], Loss: 0.7553, time: 20:51:34.419433\n",
      "Epoch [20900/30000], Loss: 0.7416, time: 20:51:35.324384\n",
      "Epoch [21000/30000], Loss: 0.7285, time: 20:51:36.221544\n",
      "Epoch [21100/30000], Loss: 0.7159, time: 20:51:37.117809\n",
      "Epoch [21200/30000], Loss: 0.7038, time: 20:51:38.016306\n",
      "Epoch [21300/30000], Loss: 0.6923, time: 20:51:38.909660\n",
      "Epoch [21400/30000], Loss: 0.6812, time: 20:51:39.806154\n",
      "Epoch [21500/30000], Loss: 0.6706, time: 20:51:40.695061\n",
      "Epoch [21600/30000], Loss: 0.6604, time: 20:51:41.588106\n",
      "Epoch [21700/30000], Loss: 0.6507, time: 20:51:42.476756\n",
      "Epoch [21800/30000], Loss: 0.6413, time: 20:51:43.363869\n",
      "Epoch [21900/30000], Loss: 0.6323, time: 20:51:44.251031\n",
      "Epoch [22000/30000], Loss: 0.6237, time: 20:51:45.142902\n",
      "Epoch [22100/30000], Loss: 0.6154, time: 20:51:46.058571\n",
      "Epoch [22200/30000], Loss: 0.6075, time: 20:51:46.957643\n",
      "Epoch [22300/30000], Loss: 0.5998, time: 20:51:47.851340\n",
      "Epoch [22400/30000], Loss: 0.5925, time: 20:51:48.744653\n",
      "Epoch [22500/30000], Loss: 0.5855, time: 20:51:49.639677\n",
      "Epoch [22600/30000], Loss: 0.5787, time: 20:51:50.531041\n",
      "Epoch [22700/30000], Loss: 0.5722, time: 20:51:51.421456\n",
      "Epoch [22800/30000], Loss: 0.5659, time: 20:51:52.315040\n",
      "Epoch [22900/30000], Loss: 0.5599, time: 20:51:53.201949\n",
      "Epoch [23000/30000], Loss: 0.5540, time: 20:51:54.092535\n",
      "Epoch [23100/30000], Loss: 0.5484, time: 20:51:54.986589\n",
      "Epoch [23200/30000], Loss: 0.5431, time: 20:51:55.877588\n",
      "Epoch [23300/30000], Loss: 0.5379, time: 20:51:56.786480\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30000\n",
    "alpha = 0.0001\n",
    "n = 16\n",
    "\n",
    "u = gradient_descent(n, alpha, m, num_epochs, trained_model, objective_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the paper \"Convergence of the forward-backward sweep method in optimal control\" by Michael McAsey et al, we know that analytical solution for this problem is:\n",
    "\n",
    "$$x(t) = \\frac{\\sqrt{2}\\cosh(\\sqrt{2}(t-1)) - \\sinh(\\sqrt{2}(t-1))}{\\sqrt{2}\\cosh(\\sqrt{2})+\\sinh{\\sqrt{2}}}$$\n",
    "$$u(t) = \\frac{\\sinh(\\sqrt{2}(t-1))}{\\sqrt{2}\\cosh(\\sqrt{2})+\\sinh{\\sqrt{2}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_586488/2452070342.py:2: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  numerator = np.sqrt(2) * np.cosh(np.sqrt(2) * (t - 1)) - np.sinh(np.sqrt(2) * (t - 1))\n",
      "/tmp/ipykernel_586488/2452070342.py:7: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  numerator = np.sinh(np.sqrt(2) * (t - 1))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f6c36bfebc0>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def analytical_x(t):\n",
    "    numerator = np.sqrt(2) * np.cosh(np.sqrt(2) * (t - 1)) - np.sinh(np.sqrt(2) * (t - 1))\n",
    "    denominator = np.sqrt(2) * np.cosh(np.sqrt(2)) + np.sinh(np.sqrt(2))\n",
    "    return numerator / denominator\n",
    "\n",
    "def analytical_u(t):\n",
    "    numerator = np.sinh(np.sqrt(2) * (t - 1))\n",
    "    denominator = np.sqrt(2) * np.cosh(np.sqrt(2)) + np.sinh(np.sqrt(2))\n",
    "    return numerator / denominator\n",
    "\n",
    "\n",
    "t = torch.linspace(0, end_time, m).unsqueeze(1) \n",
    "plt.plot(analytical_x(t), label=\"Analytical x\")\n",
    "t = torch.linspace(0, end_time, m, device=device)\n",
    "\n",
    "x = trained_model(u.unsqueeze(0),t.unsqueeze(1)).cpu().detach().numpy().T\n",
    "plt.plot(x, label=\"Found x\")\n",
    "t = torch.linspace(0, end_time, m).unsqueeze(1) \n",
    "plt.plot(analytical_u(t), label=\"Analytical u\")\n",
    "plt.plot(u.cpu().detach().numpy().T, label=\"Found u\")\n",
    "plt.legend()\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
